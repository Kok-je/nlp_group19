{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:12:34.734331Z",
     "start_time": "2025-04-09T09:12:31.390627Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x111f27250>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nikhilsultania/Library/Caches/pypoetry/virtualenvs/nlp-group19-roMxBzuk-py3.11/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:19:30.325550Z",
     "start_time": "2025-04-09T09:19:30.323251Z"
    }
   },
   "source": [
    "DEVICE = torch.device(\"mps\")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:20:54.269415Z",
     "start_time": "2025-04-09T09:19:31.179946Z"
    }
   },
   "source": [
    "STUDENT_MODEL = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(STUDENT_MODEL, num_labels=3).to(DEVICE)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b162187aa2349769d051a9c70f5a6f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d7bcecf635d426bb4144045f1c49fbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:20:56.628666Z",
     "start_time": "2025-04-09T09:20:54.292043Z"
    }
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(STUDENT_MODEL)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96830f18488a4b8f86b987af8d529205"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c37a9894a100473d8aea70b32b0e1452"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "461e61874c0f4e63a52e4f9f3b64f26d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:20:56.646449Z",
     "start_time": "2025-04-09T09:20:56.644105Z"
    }
   },
   "source": [
    "model.config.id2label = {0: \"background\", 1: \"result\", 2: \"method\"}\n",
    "model.config.label2id = {\"background\": 0, \"result\": 1, \"method\": 2}"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:18:23.227658Z",
     "start_time": "2025-04-09T09:18:23.187500Z"
    }
   },
   "source": "train_dataset = pd.read_csv(\"../data/train_cleaned.csv\")",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:21:04.760209Z",
     "start_time": "2025-04-09T09:21:04.749550Z"
    }
   },
   "source": [
    "train_dataset.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0    source  citeEnd  \\\n",
       "0           0  explicit    175.0   \n",
       "1           1  explicit     36.0   \n",
       "2           2  explicit    228.0   \n",
       "3           3  explicit    110.0   \n",
       "4           4  explicit    239.0   \n",
       "\n",
       "                                         sectionName  citeStart  \\\n",
       "0                                       Introduction      168.0   \n",
       "1  Novel Quantitative Trait Loci for Seminal Root...       16.0   \n",
       "2                                       Introduction      225.0   \n",
       "3                                         Discussion       46.0   \n",
       "4                                         Discussion      234.0   \n",
       "\n",
       "                                              string       label  \\\n",
       "0  However, how frataxin interacts with the Fe-S ...  background   \n",
       "1  In the study by Hickey et al. (2012), spikes w...  background   \n",
       "2  The drug also reduces catecholamine secretion,...  background   \n",
       "3  By clustering with lowly aggressive close kin ...  background   \n",
       "4  Ophthalmic symptoms are rare manifestations of...  background   \n",
       "\n",
       "   label_confidence                             citingPaperId  \\\n",
       "0               1.0  1872080baa7d30ec8fb87be9a65358cd3a7fb649   \n",
       "1               1.0  ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b   \n",
       "2               1.0  9cdf605beb1aa1078f235c4332b3024daa8b31dc   \n",
       "3               1.0  d9f3207db0c79a3b154f3875c9760cc6b056904b   \n",
       "4               1.0  88b86556857f4374842d2af2e359576806239175   \n",
       "\n",
       "                               citedPaperId  isKeyCitation  \\\n",
       "0  894be9b4ea46a5c422e81ef3c241072d4c73fdc0           True   \n",
       "1  b6642e19efb8db5623b3cc4eef1c5822a6151107           True   \n",
       "2  4e6a17fb8d7a3cada601d942e22eb5da6d01adbd          False   \n",
       "3  2cc6ff899bf17666ad35893524a4d61624555ed7          False   \n",
       "4  a5bb0ff1a026944d2a47a155462959af2b8505a8          False   \n",
       "\n",
       "                                                  id  \\\n",
       "0  1872080baa7d30ec8fb87be9a65358cd3a7fb649>894be...   \n",
       "1  ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b>b6642...   \n",
       "2  9cdf605beb1aa1078f235c4332b3024daa8b31dc>4e6a1...   \n",
       "3  d9f3207db0c79a3b154f3875c9760cc6b056904b>2cc6f...   \n",
       "4  88b86556857f4374842d2af2e359576806239175>a5bb0...   \n",
       "\n",
       "                                           unique_id  excerpt_index label2  \\\n",
       "0  1872080baa7d30ec8fb87be9a65358cd3a7fb649>894be...             11    NaN   \n",
       "1  ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b>b6642...              2    NaN   \n",
       "2  9cdf605beb1aa1078f235c4332b3024daa8b31dc>4e6a1...              0    NaN   \n",
       "3  d9f3207db0c79a3b154f3875c9760cc6b056904b>2cc6f...              3    NaN   \n",
       "4  88b86556857f4374842d2af2e359576806239175>a5bb0...              2    NaN   \n",
       "\n",
       "   label2_confidence  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>citeEnd</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>citeStart</th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "      <th>label_confidence</th>\n",
       "      <th>citingPaperId</th>\n",
       "      <th>citedPaperId</th>\n",
       "      <th>isKeyCitation</th>\n",
       "      <th>id</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>excerpt_index</th>\n",
       "      <th>label2</th>\n",
       "      <th>label2_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explicit</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>168.0</td>\n",
       "      <td>However, how frataxin interacts with the Fe-S ...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1872080baa7d30ec8fb87be9a65358cd3a7fb649</td>\n",
       "      <td>894be9b4ea46a5c422e81ef3c241072d4c73fdc0</td>\n",
       "      <td>True</td>\n",
       "      <td>1872080baa7d30ec8fb87be9a65358cd3a7fb649&gt;894be...</td>\n",
       "      <td>1872080baa7d30ec8fb87be9a65358cd3a7fb649&gt;894be...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>explicit</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Novel Quantitative Trait Loci for Seminal Root...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>In the study by Hickey et al. (2012), spikes w...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b</td>\n",
       "      <td>b6642e19efb8db5623b3cc4eef1c5822a6151107</td>\n",
       "      <td>True</td>\n",
       "      <td>ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b&gt;b6642...</td>\n",
       "      <td>ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b&gt;b6642...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>explicit</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>225.0</td>\n",
       "      <td>The drug also reduces catecholamine secretion,...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9cdf605beb1aa1078f235c4332b3024daa8b31dc</td>\n",
       "      <td>4e6a17fb8d7a3cada601d942e22eb5da6d01adbd</td>\n",
       "      <td>False</td>\n",
       "      <td>9cdf605beb1aa1078f235c4332b3024daa8b31dc&gt;4e6a1...</td>\n",
       "      <td>9cdf605beb1aa1078f235c4332b3024daa8b31dc&gt;4e6a1...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>explicit</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>46.0</td>\n",
       "      <td>By clustering with lowly aggressive close kin ...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>d9f3207db0c79a3b154f3875c9760cc6b056904b</td>\n",
       "      <td>2cc6ff899bf17666ad35893524a4d61624555ed7</td>\n",
       "      <td>False</td>\n",
       "      <td>d9f3207db0c79a3b154f3875c9760cc6b056904b&gt;2cc6f...</td>\n",
       "      <td>d9f3207db0c79a3b154f3875c9760cc6b056904b&gt;2cc6f...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>explicit</td>\n",
       "      <td>239.0</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Ophthalmic symptoms are rare manifestations of...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88b86556857f4374842d2af2e359576806239175</td>\n",
       "      <td>a5bb0ff1a026944d2a47a155462959af2b8505a8</td>\n",
       "      <td>False</td>\n",
       "      <td>88b86556857f4374842d2af2e359576806239175&gt;a5bb0...</td>\n",
       "      <td>88b86556857f4374842d2af2e359576806239175&gt;a5bb0...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:21:06.762033Z",
     "start_time": "2025-04-09T09:21:06.754165Z"
    }
   },
   "source": [
    "labels = train_dataset[\"label\"]\n",
    "train_dataset = train_dataset.drop(columns=[\"Unnamed: 0\", \"label\"])"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:21:08.373091Z",
     "start_time": "2025-04-09T09:21:08.181716Z"
    }
   },
   "source": [
    "input_strings = []\n",
    "for i in range(len(train_dataset)):\n",
    "    json_object = train_dataset.iloc[i].to_json()\n",
    "    input_strings.append(str(json_object))\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOBE PROCESSED LATER\n",
    "# input_strings = [i for i in input_strings if len(i) <= 1024]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:21:31.002172Z",
     "start_time": "2025-04-09T09:21:10.350406Z"
    }
   },
   "source": [
    "count = 0\n",
    "for i in range(len(input_strings)):\n",
    "    tokenized = tokenizer(input_strings[i], return_tensors=\"pt\", padding=\"max_length\", max_length=512, truncation=True).to(DEVICE) \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized)\n",
    "    probs = F.softmax(outputs.logits, dim=1)\n",
    "    predicted_class_id = torch.argmax(probs).item()\n",
    "    label = model.config.id2label[predicted_class_id]\n",
    "    if label == labels[i]:\n",
    "        count += 1"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      5\u001B[39m     outputs = model(**tokenized)\n\u001B[32m      6\u001B[39m probs = F.softmax(outputs.logits, dim=\u001B[32m1\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m predicted_class_id = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m label = model.config.id2label[predicted_class_id]\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m label == labels[i]:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2266\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8194\n"
     ]
    }
   ],
   "source": [
    "print(len(input_strings))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T09:21:42.601057Z",
     "start_time": "2025-04-09T09:21:41.776004Z"
    }
   },
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"./results/Teachers/Ours/deepseek-openai/deepseek_openai_combined.csv\")[\"train\"].remove_columns(\"Unnamed: 0\")\n",
    "dataset = dataset.add_column(\"input\", input_strings)\n",
    "# dataset[\"train\"] = dataset[\"train\"].add_column(\"input\", input_strings)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(row):\n",
    "    input_text = row[\"input\"]\n",
    "    rationale = row[\"reasoning\"]\n",
    "    label = model.config.label2id[row[\"model_classification\"]]\n",
    "\n",
    "    input_enc = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=512).to(DEVICE)\n",
    "    rationale_enc = tokenizer(rationale, truncation=True, padding=\"max_length\", max_length=512).to(DEVICE)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_enc[\"input_ids\"],\n",
    "        \"attention_mask\": input_enc[\"attention_mask\"],\n",
    "        \"labels\": label,\n",
    "        \"rationale_ids\": rationale_enc[\"input_ids\"],\n",
    "        \"rationale_mask\": rationale_enc[\"attention_mask\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8194/8194 [00:06<00:00, 1292.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "processed_dataset = dataset.map(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'model_classification', 'reasoning', 'input', 'input_ids', 'attention_mask', 'labels', 'rationale_ids', 'rationale_mask'],\n",
       "    num_rows: 8194\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3234.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "processed_dataset.save_to_disk(\"processed_datset_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        rationale_ids = inputs.pop(\"rationale_ids\", None)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        label_loss = loss_fn(outputs.logits, labels)\n",
    "        \n",
    "        if rationale_ids is not None:\n",
    "            rationale_outputs = model(input_ids=rationale_ids, attention_mask=inputs[\"attention_mask\"])\n",
    "            rationale_loss = loss_fn(rationale_outputs.logits, rationale_ids)\n",
    "            loss = label_loss + 0.5 * rationale_loss  # Weighted loss\n",
    "        else:\n",
    "            loss = label_loss\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "trainer = MultiTaskTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_dataset,\n",
    "    eval_dataset=processed_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3075' max='3075' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3075/3075 1:04:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.704600</td>\n",
       "      <td>0.740657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>0.447692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.405500</td>\n",
       "      <td>0.343345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3075, training_loss=0.5804944064752843, metrics={'train_runtime': 3858.9428, 'train_samples_per_second': 6.37, 'train_steps_per_second': 0.797, 'total_flos': 6467854034589696.0, 'train_loss': 0.5804944064752843, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(input_strings)):\n",
    "    tokenized = tokenizer(input_strings[i], return_tensors=\"pt\", padding=\"max_length\", max_length=512, truncation=True).to(DEVICE) \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized)\n",
    "    probs = F.softmax(outputs.logits, dim=1)\n",
    "    predicted_class_id = torch.argmax(probs).item()\n",
    "    label = model.config.id2label[predicted_class_id]\n",
    "    if label == labels[i]:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6179"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = input_strings[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"source\":\"explicit\",\"citeEnd\":101.0,\"sectionName\":\"Introduction\",\"citeStart\":80.0,\"string\":\"DOI: 10.7554\\\\/eLife.08828 1 of 27\\\\nmitochondrial division (Friedman et al., 2011; Korobova et al., 2013; Murley et al., 2013; Korobova et al., 2014).\",\"label_confidence\":0.7834,\"citingPaperId\":\"929a7548464ce1d9d785abbe35da34842c0133e6\",\"citedPaperId\":\"21096eb950bdff77308ad3924d69b681589bdc91\",\"isKeyCitation\":true,\"id\":\"929a7548464ce1d9d785abbe35da34842c0133e6>21096eb950bdff77308ad3924d69b681589bdc91\",\"unique_id\":\"929a7548464ce1d9d785abbe35da34842c0133e6>21096eb950bdff77308ad3924d69b681589bdc91_11\",\"excerpt_index\":11,\"label2\":null,\"label2_confidence\":null}'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer(string, return_tensors=\"pt\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1063,  1000,  3120,  1000,  1024,  1000, 13216,  1000,  1010,\n",
       "          1000, 21893, 10497,  1000,  1024,  7886,  1012,  1014,  1010,  1000,\n",
       "          2930, 18442,  1000,  1024,  1000,  4955,  1000,  1010,  1000, 17248,\n",
       "          7559,  2102,  1000,  1024,  3770,  1012,  1014,  1010,  1000,  5164,\n",
       "          1000,  1024,  1000,  9193,  1024,  2184,  1012,  4293, 27009,  1032,\n",
       "          1013, 12005,  7959,  1012,  5511,  2620, 22407,  1015,  1997,  2676,\n",
       "          1032, 22484,  3406, 24561, 13626,  4818,  2407,  1006, 18486,  3802,\n",
       "          2632,  1012,  1010,  2249,  1025, 12849,  3217,  5092,  3567,  3802,\n",
       "          2632,  1012,  1010,  2286,  1025, 14163, 12866,  3802,  2632,  1012,\n",
       "          1010,  2286,  1025, 12849,  3217,  5092,  3567,  3802,  2632,  1012,\n",
       "          1010,  2297,  1007,  1012,  1000,  1010,  1000,  3830,  1035,  7023,\n",
       "          1000,  1024,  1014,  1012,  6275, 22022,  1010,  1000,  8951, 23298,\n",
       "          3593,  1000,  1024,  1000,  6227,  2683,  2050, 23352, 18139, 21472,\n",
       "          2549,  3401,  2487,  2094,  2683,  2094,  2581, 27531,  7875,  4783,\n",
       "         19481,  2850, 22022,  2620, 20958,  2278, 24096, 22394,  2063,  2575,\n",
       "          1000,  1010,  1000,  6563, 23298,  3593,  1000,  1024,  1000, 12875,\n",
       "          2683,  2575, 15878,  2683, 12376,  2497, 20952,  2546,  2581,  2581,\n",
       "         14142,  2620,  4215, 23499, 18827,  2094,  2575,  2683,  2497,  2575,\n",
       "          2620, 16068,  2620,  2683,  2497, 16409,  2683,  2487,  1000,  1010,\n",
       "          1000,  2003, 14839, 26243,  3370,  1000,  1024,  2995,  1010,  1000,\n",
       "          8909,  1000,  1024,  1000,  6227,  2683,  2050, 23352, 18139, 21472,\n",
       "          2549,  3401,  2487,  2094,  2683,  2094,  2581, 27531,  7875,  4783,\n",
       "         19481,  2850, 22022,  2620, 20958,  2278, 24096, 22394,  2063,  2575,\n",
       "          1028, 12875,  2683,  2575, 15878,  2683, 12376,  2497, 20952,  2546,\n",
       "          2581,  2581, 14142,  2620,  4215, 23499, 18827,  2094,  2575,  2683,\n",
       "          2497,  2575,  2620, 16068,  2620,  2683,  2497, 16409,  2683,  2487,\n",
       "          1000,  1010,  1000,  4310,  1035,  8909,  1000,  1024,  1000,  6227,\n",
       "          2683,  2050, 23352, 18139, 21472,  2549,  3401,  2487,  2094,  2683,\n",
       "          2094,  2581, 27531,  7875,  4783, 19481,  2850, 22022,  2620, 20958,\n",
       "          2278, 24096, 22394,  2063,  2575,  1028, 12875,  2683,  2575, 15878,\n",
       "          2683, 12376,  2497, 20952,  2546,  2581,  2581, 14142,  2620,  4215,\n",
       "         23499, 18827,  2094,  2575,  2683,  2497,  2575,  2620, 16068,  2620,\n",
       "          2683,  2497, 16409,  2683,  2487,  1035,  2340,  1000,  1010,  1000,\n",
       "         28142,  1035,  5950,  1000,  1024,  2340,  1010,  1000,  3830,  2475,\n",
       "          1000,  1024, 19701,  1010,  1000,  3830,  2475,  1035,  7023,  1000,\n",
       "          1024, 19701,  1065,   102]], device='mps:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "       device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='mps:0')}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_output = trainer.predict(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.301876  , -2.359562  , -0.89601904],\n",
       "       [-0.78595185, -1.7958096 ,  3.4897745 ],\n",
       "       [ 4.282859  , -2.3421915 , -0.87154573],\n",
       "       ...,\n",
       "       [ 3.2073004 , -0.42851496, -1.4330306 ],\n",
       "       [ 3.555149  , -0.9191982 , -1.2913921 ],\n",
       "       [ 4.308708  , -2.3498607 , -0.8902831 ]],\n",
       "      shape=(8194, 3), dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_output.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = trainer_output.predictions.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, ..., 0, 0, 0], shape=(8194,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'background'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label[p[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6179\n"
     ]
    }
   ],
   "source": [
    "new_count = 0\n",
    "for i in range(len(labels)):\n",
    "    if model.config.id2label[p[i]] == labels[i]:\n",
    "        new_count += 1\n",
    "print(new_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
