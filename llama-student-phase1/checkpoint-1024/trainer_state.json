{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9978032706858677,
  "eval_steps": 500,
  "global_step": 1024,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01952648279228704,
      "grad_norm": 0.46833449602127075,
      "learning_rate": 9.90234375e-05,
      "loss": 0.4408,
      "step": 10
    },
    {
      "epoch": 0.03905296558457408,
      "grad_norm": 0.5292803645133972,
      "learning_rate": 9.8046875e-05,
      "loss": 0.4311,
      "step": 20
    },
    {
      "epoch": 0.05857944837686112,
      "grad_norm": 0.6063548922538757,
      "learning_rate": 9.70703125e-05,
      "loss": 0.44,
      "step": 30
    },
    {
      "epoch": 0.07810593116914816,
      "grad_norm": 0.5405473113059998,
      "learning_rate": 9.609375e-05,
      "loss": 0.4366,
      "step": 40
    },
    {
      "epoch": 0.0976324139614352,
      "grad_norm": 0.4634726941585541,
      "learning_rate": 9.51171875e-05,
      "loss": 0.4572,
      "step": 50
    },
    {
      "epoch": 0.11715889675372224,
      "grad_norm": 0.47444942593574524,
      "learning_rate": 9.4140625e-05,
      "loss": 0.4363,
      "step": 60
    },
    {
      "epoch": 0.13668537954600926,
      "grad_norm": 0.5824015736579895,
      "learning_rate": 9.31640625e-05,
      "loss": 0.4574,
      "step": 70
    },
    {
      "epoch": 0.15621186233829631,
      "grad_norm": 0.5268400311470032,
      "learning_rate": 9.21875e-05,
      "loss": 0.4507,
      "step": 80
    },
    {
      "epoch": 0.17573834513058334,
      "grad_norm": 0.544717013835907,
      "learning_rate": 9.121093750000001e-05,
      "loss": 0.4304,
      "step": 90
    },
    {
      "epoch": 0.1952648279228704,
      "grad_norm": 0.5896193981170654,
      "learning_rate": 9.023437500000001e-05,
      "loss": 0.4359,
      "step": 100
    },
    {
      "epoch": 0.21479131071515742,
      "grad_norm": 0.5469614267349243,
      "learning_rate": 8.925781250000001e-05,
      "loss": 0.4385,
      "step": 110
    },
    {
      "epoch": 0.23431779350744447,
      "grad_norm": 0.5486722588539124,
      "learning_rate": 8.828125000000001e-05,
      "loss": 0.4285,
      "step": 120
    },
    {
      "epoch": 0.2538442762997315,
      "grad_norm": 0.5309960246086121,
      "learning_rate": 8.730468750000001e-05,
      "loss": 0.4492,
      "step": 130
    },
    {
      "epoch": 0.2733707590920185,
      "grad_norm": 0.5447695851325989,
      "learning_rate": 8.6328125e-05,
      "loss": 0.4569,
      "step": 140
    },
    {
      "epoch": 0.2928972418843056,
      "grad_norm": 0.5864415168762207,
      "learning_rate": 8.53515625e-05,
      "loss": 0.4364,
      "step": 150
    },
    {
      "epoch": 0.31242372467659263,
      "grad_norm": 0.5151829719543457,
      "learning_rate": 8.4375e-05,
      "loss": 0.4692,
      "step": 160
    },
    {
      "epoch": 0.33195020746887965,
      "grad_norm": 0.5721909999847412,
      "learning_rate": 8.33984375e-05,
      "loss": 0.4469,
      "step": 170
    },
    {
      "epoch": 0.3514766902611667,
      "grad_norm": 0.5614235401153564,
      "learning_rate": 8.2421875e-05,
      "loss": 0.4441,
      "step": 180
    },
    {
      "epoch": 0.37100317305345376,
      "grad_norm": 0.6067898273468018,
      "learning_rate": 8.14453125e-05,
      "loss": 0.4458,
      "step": 190
    },
    {
      "epoch": 0.3905296558457408,
      "grad_norm": 0.5667968392372131,
      "learning_rate": 8.046875e-05,
      "loss": 0.4562,
      "step": 200
    },
    {
      "epoch": 0.4100561386380278,
      "grad_norm": 0.47544699907302856,
      "learning_rate": 7.94921875e-05,
      "loss": 0.4418,
      "step": 210
    },
    {
      "epoch": 0.42958262143031484,
      "grad_norm": 0.5631621479988098,
      "learning_rate": 7.8515625e-05,
      "loss": 0.4728,
      "step": 220
    },
    {
      "epoch": 0.4491091042226019,
      "grad_norm": 0.5585248470306396,
      "learning_rate": 7.75390625e-05,
      "loss": 0.4348,
      "step": 230
    },
    {
      "epoch": 0.46863558701488894,
      "grad_norm": 0.5610130429267883,
      "learning_rate": 7.65625e-05,
      "loss": 0.4458,
      "step": 240
    },
    {
      "epoch": 0.48816206980717597,
      "grad_norm": 0.5861376523971558,
      "learning_rate": 7.558593750000001e-05,
      "loss": 0.4353,
      "step": 250
    },
    {
      "epoch": 0.507688552599463,
      "grad_norm": 0.5038818120956421,
      "learning_rate": 7.460937500000001e-05,
      "loss": 0.4596,
      "step": 260
    },
    {
      "epoch": 0.5272150353917501,
      "grad_norm": 0.5712352991104126,
      "learning_rate": 7.363281250000001e-05,
      "loss": 0.4549,
      "step": 270
    },
    {
      "epoch": 0.546741518184037,
      "grad_norm": 0.5390405654907227,
      "learning_rate": 7.265625000000001e-05,
      "loss": 0.4701,
      "step": 280
    },
    {
      "epoch": 0.5662680009763241,
      "grad_norm": 0.5136329531669617,
      "learning_rate": 7.16796875e-05,
      "loss": 0.4189,
      "step": 290
    },
    {
      "epoch": 0.5857944837686112,
      "grad_norm": 0.5250381827354431,
      "learning_rate": 7.0703125e-05,
      "loss": 0.448,
      "step": 300
    },
    {
      "epoch": 0.6053209665608982,
      "grad_norm": 0.5815063714981079,
      "learning_rate": 6.97265625e-05,
      "loss": 0.4627,
      "step": 310
    },
    {
      "epoch": 0.6248474493531853,
      "grad_norm": 0.6248559951782227,
      "learning_rate": 6.875e-05,
      "loss": 0.4423,
      "step": 320
    },
    {
      "epoch": 0.6443739321454723,
      "grad_norm": 0.5689378380775452,
      "learning_rate": 6.77734375e-05,
      "loss": 0.4232,
      "step": 330
    },
    {
      "epoch": 0.6639004149377593,
      "grad_norm": 0.5051409602165222,
      "learning_rate": 6.6796875e-05,
      "loss": 0.4552,
      "step": 340
    },
    {
      "epoch": 0.6834268977300464,
      "grad_norm": 0.523993968963623,
      "learning_rate": 6.58203125e-05,
      "loss": 0.4671,
      "step": 350
    },
    {
      "epoch": 0.7029533805223334,
      "grad_norm": 0.6525366306304932,
      "learning_rate": 6.484375e-05,
      "loss": 0.4289,
      "step": 360
    },
    {
      "epoch": 0.7224798633146204,
      "grad_norm": 0.5194088220596313,
      "learning_rate": 6.38671875e-05,
      "loss": 0.4232,
      "step": 370
    },
    {
      "epoch": 0.7420063461069075,
      "grad_norm": 0.5923383831977844,
      "learning_rate": 6.2890625e-05,
      "loss": 0.4611,
      "step": 380
    },
    {
      "epoch": 0.7615328288991945,
      "grad_norm": 0.6024882793426514,
      "learning_rate": 6.19140625e-05,
      "loss": 0.4529,
      "step": 390
    },
    {
      "epoch": 0.7810593116914816,
      "grad_norm": 0.5636802315711975,
      "learning_rate": 6.0937500000000004e-05,
      "loss": 0.4375,
      "step": 400
    },
    {
      "epoch": 0.8005857944837687,
      "grad_norm": 0.6093804240226746,
      "learning_rate": 5.99609375e-05,
      "loss": 0.4374,
      "step": 410
    },
    {
      "epoch": 0.8201122772760556,
      "grad_norm": 0.5643161535263062,
      "learning_rate": 5.8984375e-05,
      "loss": 0.4288,
      "step": 420
    },
    {
      "epoch": 0.8396387600683427,
      "grad_norm": 0.664034903049469,
      "learning_rate": 5.80078125e-05,
      "loss": 0.4634,
      "step": 430
    },
    {
      "epoch": 0.8591652428606297,
      "grad_norm": 0.5801329612731934,
      "learning_rate": 5.703125e-05,
      "loss": 0.4576,
      "step": 440
    },
    {
      "epoch": 0.8786917256529168,
      "grad_norm": 0.6367512941360474,
      "learning_rate": 5.60546875e-05,
      "loss": 0.4451,
      "step": 450
    },
    {
      "epoch": 0.8982182084452038,
      "grad_norm": 0.5524291396141052,
      "learning_rate": 5.5078125000000006e-05,
      "loss": 0.4418,
      "step": 460
    },
    {
      "epoch": 0.9177446912374908,
      "grad_norm": 0.5339697599411011,
      "learning_rate": 5.4101562500000005e-05,
      "loss": 0.4417,
      "step": 470
    },
    {
      "epoch": 0.9372711740297779,
      "grad_norm": 0.6298989653587341,
      "learning_rate": 5.3125000000000004e-05,
      "loss": 0.4395,
      "step": 480
    },
    {
      "epoch": 0.956797656822065,
      "grad_norm": 0.5530120134353638,
      "learning_rate": 5.21484375e-05,
      "loss": 0.4205,
      "step": 490
    },
    {
      "epoch": 0.9763241396143519,
      "grad_norm": 0.6235972046852112,
      "learning_rate": 5.1171875e-05,
      "loss": 0.4615,
      "step": 500
    },
    {
      "epoch": 0.995850622406639,
      "grad_norm": 0.5854769349098206,
      "learning_rate": 5.01953125e-05,
      "loss": 0.445,
      "step": 510
    },
    {
      "epoch": 1.0136685379546009,
      "grad_norm": 0.6241284608840942,
      "learning_rate": 4.921875e-05,
      "loss": 0.4366,
      "step": 520
    },
    {
      "epoch": 1.033195020746888,
      "grad_norm": 0.5851650238037109,
      "learning_rate": 4.82421875e-05,
      "loss": 0.4558,
      "step": 530
    },
    {
      "epoch": 1.052721503539175,
      "grad_norm": 0.5202475786209106,
      "learning_rate": 4.7265625000000005e-05,
      "loss": 0.4261,
      "step": 540
    },
    {
      "epoch": 1.072247986331462,
      "grad_norm": 0.5755003094673157,
      "learning_rate": 4.6289062500000005e-05,
      "loss": 0.4488,
      "step": 550
    },
    {
      "epoch": 1.091774469123749,
      "grad_norm": 0.6050779223442078,
      "learning_rate": 4.5312500000000004e-05,
      "loss": 0.4561,
      "step": 560
    },
    {
      "epoch": 1.1113009519160362,
      "grad_norm": 0.5606256723403931,
      "learning_rate": 4.43359375e-05,
      "loss": 0.4371,
      "step": 570
    },
    {
      "epoch": 1.1308274347083231,
      "grad_norm": 0.7041599154472351,
      "learning_rate": 4.3359375e-05,
      "loss": 0.4234,
      "step": 580
    },
    {
      "epoch": 1.1503539175006101,
      "grad_norm": 0.5731141567230225,
      "learning_rate": 4.23828125e-05,
      "loss": 0.4581,
      "step": 590
    },
    {
      "epoch": 1.1698804002928973,
      "grad_norm": 0.637358546257019,
      "learning_rate": 4.140625e-05,
      "loss": 0.4315,
      "step": 600
    },
    {
      "epoch": 1.1894068830851843,
      "grad_norm": 0.5849858522415161,
      "learning_rate": 4.04296875e-05,
      "loss": 0.4284,
      "step": 610
    },
    {
      "epoch": 1.2089333658774712,
      "grad_norm": 0.6418049335479736,
      "learning_rate": 3.9453125000000005e-05,
      "loss": 0.451,
      "step": 620
    },
    {
      "epoch": 1.2284598486697584,
      "grad_norm": 0.5767452120780945,
      "learning_rate": 3.8476562500000004e-05,
      "loss": 0.4237,
      "step": 630
    },
    {
      "epoch": 1.2479863314620454,
      "grad_norm": 0.6119236350059509,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.4352,
      "step": 640
    },
    {
      "epoch": 1.2675128142543324,
      "grad_norm": 0.6451457738876343,
      "learning_rate": 3.65234375e-05,
      "loss": 0.4498,
      "step": 650
    },
    {
      "epoch": 1.2870392970466193,
      "grad_norm": 0.6390671133995056,
      "learning_rate": 3.5546875e-05,
      "loss": 0.4217,
      "step": 660
    },
    {
      "epoch": 1.3065657798389065,
      "grad_norm": 0.6614833474159241,
      "learning_rate": 3.45703125e-05,
      "loss": 0.4536,
      "step": 670
    },
    {
      "epoch": 1.3260922626311935,
      "grad_norm": 0.587180495262146,
      "learning_rate": 3.359375e-05,
      "loss": 0.4137,
      "step": 680
    },
    {
      "epoch": 1.3456187454234807,
      "grad_norm": 0.6412255764007568,
      "learning_rate": 3.26171875e-05,
      "loss": 0.4425,
      "step": 690
    },
    {
      "epoch": 1.3651452282157677,
      "grad_norm": 0.6005392074584961,
      "learning_rate": 3.1640625e-05,
      "loss": 0.4386,
      "step": 700
    },
    {
      "epoch": 1.3846717110080546,
      "grad_norm": 0.6789030432701111,
      "learning_rate": 3.0664062500000004e-05,
      "loss": 0.4377,
      "step": 710
    },
    {
      "epoch": 1.4041981938003416,
      "grad_norm": 0.5960841774940491,
      "learning_rate": 2.96875e-05,
      "loss": 0.4105,
      "step": 720
    },
    {
      "epoch": 1.4237246765926288,
      "grad_norm": 0.6487800478935242,
      "learning_rate": 2.8710937500000002e-05,
      "loss": 0.4561,
      "step": 730
    },
    {
      "epoch": 1.4432511593849158,
      "grad_norm": 0.6048291325569153,
      "learning_rate": 2.7734375e-05,
      "loss": 0.4561,
      "step": 740
    },
    {
      "epoch": 1.462777642177203,
      "grad_norm": 0.5683003067970276,
      "learning_rate": 2.67578125e-05,
      "loss": 0.4235,
      "step": 750
    },
    {
      "epoch": 1.48230412496949,
      "grad_norm": 0.5846489667892456,
      "learning_rate": 2.578125e-05,
      "loss": 0.4303,
      "step": 760
    },
    {
      "epoch": 1.501830607761777,
      "grad_norm": 0.6208922863006592,
      "learning_rate": 2.4804687500000002e-05,
      "loss": 0.4237,
      "step": 770
    },
    {
      "epoch": 1.5213570905540639,
      "grad_norm": 0.5992240905761719,
      "learning_rate": 2.3828125e-05,
      "loss": 0.4388,
      "step": 780
    },
    {
      "epoch": 1.5408835733463508,
      "grad_norm": 0.6004472970962524,
      "learning_rate": 2.28515625e-05,
      "loss": 0.4226,
      "step": 790
    },
    {
      "epoch": 1.560410056138638,
      "grad_norm": 0.5856256484985352,
      "learning_rate": 2.1875e-05,
      "loss": 0.4369,
      "step": 800
    },
    {
      "epoch": 1.5799365389309252,
      "grad_norm": 0.6621381640434265,
      "learning_rate": 2.0898437500000002e-05,
      "loss": 0.4552,
      "step": 810
    },
    {
      "epoch": 1.5994630217232122,
      "grad_norm": 0.6324066519737244,
      "learning_rate": 1.9921875e-05,
      "loss": 0.4504,
      "step": 820
    },
    {
      "epoch": 1.6189895045154992,
      "grad_norm": 0.6009923815727234,
      "learning_rate": 1.89453125e-05,
      "loss": 0.4353,
      "step": 830
    },
    {
      "epoch": 1.6385159873077861,
      "grad_norm": 0.647051990032196,
      "learning_rate": 1.796875e-05,
      "loss": 0.4364,
      "step": 840
    },
    {
      "epoch": 1.658042470100073,
      "grad_norm": 0.6508236527442932,
      "learning_rate": 1.6992187500000002e-05,
      "loss": 0.414,
      "step": 850
    },
    {
      "epoch": 1.6775689528923603,
      "grad_norm": 0.6159039735794067,
      "learning_rate": 1.6015625e-05,
      "loss": 0.443,
      "step": 860
    },
    {
      "epoch": 1.6970954356846473,
      "grad_norm": 0.5954079031944275,
      "learning_rate": 1.50390625e-05,
      "loss": 0.4648,
      "step": 870
    },
    {
      "epoch": 1.7166219184769345,
      "grad_norm": 0.626289963722229,
      "learning_rate": 1.4062500000000001e-05,
      "loss": 0.4517,
      "step": 880
    },
    {
      "epoch": 1.7361484012692214,
      "grad_norm": 0.5487650632858276,
      "learning_rate": 1.30859375e-05,
      "loss": 0.4294,
      "step": 890
    },
    {
      "epoch": 1.7556748840615084,
      "grad_norm": 0.6515801548957825,
      "learning_rate": 1.2109375000000001e-05,
      "loss": 0.421,
      "step": 900
    },
    {
      "epoch": 1.7752013668537954,
      "grad_norm": 0.6262390613555908,
      "learning_rate": 1.11328125e-05,
      "loss": 0.429,
      "step": 910
    },
    {
      "epoch": 1.7947278496460823,
      "grad_norm": 0.6473081707954407,
      "learning_rate": 1.0156250000000001e-05,
      "loss": 0.4604,
      "step": 920
    },
    {
      "epoch": 1.8142543324383695,
      "grad_norm": 0.6768396496772766,
      "learning_rate": 9.1796875e-06,
      "loss": 0.4447,
      "step": 930
    },
    {
      "epoch": 1.8337808152306567,
      "grad_norm": 0.6391552686691284,
      "learning_rate": 8.203125000000001e-06,
      "loss": 0.4428,
      "step": 940
    },
    {
      "epoch": 1.8533072980229437,
      "grad_norm": 0.5411052703857422,
      "learning_rate": 7.2265625e-06,
      "loss": 0.4301,
      "step": 950
    },
    {
      "epoch": 1.8728337808152307,
      "grad_norm": 0.5956570506095886,
      "learning_rate": 6.25e-06,
      "loss": 0.43,
      "step": 960
    },
    {
      "epoch": 1.8923602636075176,
      "grad_norm": 0.5789576172828674,
      "learning_rate": 5.2734375e-06,
      "loss": 0.428,
      "step": 970
    },
    {
      "epoch": 1.9118867463998046,
      "grad_norm": 0.7473463416099548,
      "learning_rate": 4.296875e-06,
      "loss": 0.4513,
      "step": 980
    },
    {
      "epoch": 1.9314132291920918,
      "grad_norm": 0.630369246006012,
      "learning_rate": 3.3203125000000002e-06,
      "loss": 0.4338,
      "step": 990
    },
    {
      "epoch": 1.9509397119843788,
      "grad_norm": 0.589907169342041,
      "learning_rate": 2.3437500000000002e-06,
      "loss": 0.4372,
      "step": 1000
    },
    {
      "epoch": 1.970466194776666,
      "grad_norm": 0.6782023906707764,
      "learning_rate": 1.3671875e-06,
      "loss": 0.4318,
      "step": 1010
    },
    {
      "epoch": 1.989992677568953,
      "grad_norm": 0.662563681602478,
      "learning_rate": 3.90625e-07,
      "loss": 0.4397,
      "step": 1020
    }
  ],
  "logging_steps": 10,
  "max_steps": 1024,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.89810388058112e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
