{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference LLM Distillation notebook: https://github.com/simranjeet97/LLM_Distillation/blob/main/LLM_Distillation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (4.51.1)\n",
      "Requirement already satisfied: filelock in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from dotenv import load_dotenv\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForSeq2SeqLM,\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HUGGINGFACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Tokenizer & Model Setup ======\n",
    "model_id = \"google-bert/bert-base-uncased\" #\"google/gemma-3-1b-it\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, token=hf_token, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\", token=hf_token, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_id, token=hf_token, trust_remote_code=True)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     token=hf_token,\n",
    "#     trust_remote_code=True,\n",
    "#     torch_dtype=torch.float16,\n",
    "# )\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\", \n",
    "                                            #  load_in_8bit=True,\n",
    "                                            #  device_map=\"auto\",\n",
    "                                            #  quantization_config=BitsAndBytesConfig(\n",
    "                                            #      load_in_8bit=True,\n",
    "                                            #      llm_int8_threshold=6.0,\n",
    "                                            #      llm_int8_enable_fp32_cpu_offload=True,\n",
    "                                            #  ),\n",
    "                                            #  trust_remote_code=True,\n",
    "                                             )\n",
    "\n",
    "\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "# lora_config = LoraConfig(\n",
    "#     r=8,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"],\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=TaskType.CAUSAL_LM\n",
    "# )\n",
    "# model = get_peft_model(model, lora_config) # TODO Why getting PEFT model? Paper and Reference notebook did not use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32102, 768)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensure tokenizer has special tokens:\n",
    "tokenizer.add_special_tokens({\n",
    "    'additional_special_tokens': ['[label]', '[rationale]']\n",
    "})\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 samples from dataset.\n"
     ]
    }
   ],
   "source": [
    "# ====== Load dataset ======\n",
    "def load_partition(path: str) -> Dataset:\n",
    "    df = pd.read_csv(path).head(1000) #.head(10)\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "dataset = load_partition(\"../Student_Training_Data/GPT.csv\") ## should be GPT.csv\n",
    "print(f\"Loaded {len(dataset)} samples from dataset.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ignore this part, just for understanding\n",
    "# encoded_text = tokenizer.tokenize(\"Paris is the what of France?\", return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# '''The model(encoded_text) call is more commonly used during training or when you want direct access \n",
    "# to the model's raw predictions, while generate() is used when you want the model to complete/continue \n",
    "# a sequence.\n",
    "# '''\n",
    "# print(encoded_text)\n",
    "\n",
    "# outputs = model(encoded_text) # different from model.generate which produces logits and loss if labels are provided.\n",
    "# print(outputs) # logits, loss (if label was given), hidden_states, attentions\n",
    "\n",
    "# completion = model.generate(encoded_text, max_length=50)\n",
    "# print(completion)\n",
    "\n",
    "# decoded_text = tokenizer.decode(completion[0], skip_special_tokens=True)\n",
    "# print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 1378.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def add_special_tokens_if_missing(tokenizer):\n",
    "    # Add task-specific tokens if not present\n",
    "    special_tokens = []\n",
    "    if \"[label]\" not in tokenizer.get_vocab():\n",
    "        special_tokens.append(\"[label]\")\n",
    "    if \"[rationale]\" not in tokenizer.get_vocab():\n",
    "        special_tokens.append(\"[rationale]\")\n",
    "    \n",
    "    if special_tokens:\n",
    "        tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
    "    return tokenizer\n",
    "\n",
    "# Update tokenizer with special tokens\n",
    "tokenizer = add_special_tokens_if_missing(tokenizer)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Create base text inputs\n",
    "    base_texts = [\n",
    "        f\"Section Name: {sn}\\nText: {txt}\" \n",
    "        for sn, txt in zip(examples[\"sectionName\"], examples[\"string\"])\n",
    "    ]\n",
    "\n",
    "    # print(f\"Base texts: {base_texts}\")\n",
    "\n",
    "    # Create task-specific inputs\n",
    "    label_inputs = [f\"[label] {text}\" for text in base_texts]\n",
    "    rationale_inputs = [f\"[rationale] {text}\" for text in base_texts]\n",
    "\n",
    "    # Tokenize base inputs (for potential shared encoder)\n",
    "    base_encoded = tokenizer(\n",
    "        base_texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256,  # Reserve space for prefixes\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Tokenize label task inputs and targets\n",
    "    label_encoded = tokenizer(\n",
    "        label_inputs,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize label targets (text labels, not indices)\n",
    "    label_targets = tokenizer(\n",
    "        examples[\"model_classification\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True, \n",
    "        max_length=32,  # Short length for class labels\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Tokenize rationale task inputs\n",
    "    rationale_encoded = tokenizer(\n",
    "        rationale_inputs,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Tokenize rationale targets\n",
    "    rationale_targets = tokenizer(\n",
    "        examples[\"reasoning\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        # Base inputs (shared between tasks)\n",
    "        \"base_input_ids\": base_encoded.input_ids,\n",
    "        \"base_attention_mask\": base_encoded.attention_mask,\n",
    "\n",
    "        # Label prediction task\n",
    "        \"label_input_ids\": label_encoded.input_ids,\n",
    "        \"label_attention_mask\": label_encoded.attention_mask,\n",
    "        \"label_target_ids\": label_targets.input_ids,\n",
    "\n",
    "        # Rationale generation task\n",
    "        \"rationale_input_ids\": rationale_encoded.input_ids,\n",
    "        \"rationale_attention_mask\": rationale_encoded.attention_mask,\n",
    "        \"rationale_target_ids\": rationale_targets.input_ids,\n",
    "    }\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    batch_size=32,\n",
    "    remove_columns=dataset.column_names  # Remove original columns\n",
    ")\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\n",
    "    \"base_input_ids\",\n",
    "    \"base_attention_mask\",\n",
    "    \"label_input_ids\",\n",
    "    \"label_attention_mask\", \n",
    "    \"label_target_ids\",\n",
    "    \"rationale_input_ids\",\n",
    "    \"rationale_attention_mask\",\n",
    "    \"rationale_target_ids\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['base_input_ids', 'base_attention_mask', 'label_input_ids', 'label_attention_mask', 'label_target_ids', 'rationale_input_ids', 'rationale_attention_mask', 'rationale_target_ids'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_input_ids': tensor([ 5568,  5570,    10, 18921,  5027,    10,   611,     6,   149,  8072,\n",
       "         14727,    77,  6815,     7,    28,     8,  4163,    18,   134,  9068,\n",
       "          2392, 17282,  3379,  3048, 19363,    38,  1223,    80,    18,   235,\n",
       "            18,   782,  9944,    28,   284,  3876,   130,  2196,    41,   196,\n",
       "             7,    75,   134,   784,  2122,     6,  2884, 13679,    27,     7,\n",
       "            75,  1265,    87,   196,     7,    76,   536,   784, 11071,  2596,\n",
       "             6,  2938,   908,    42,    27,  7331,  2596,    87,   196,     7,\n",
       "            26,  2596,   784,  2534,     6,  1808,   908,   137,     1,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'base_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'label_input_ids': tensor([32100,  5568,  5570,    10, 18921,  5027,    10,   611,     6,   149,\n",
       "          8072, 14727,    77,  6815,     7,    28,     8,  4163,    18,   134,\n",
       "          9068,  2392, 17282,  3379,  3048, 19363,    38,  1223,    80,    18,\n",
       "           235,    18,   782,  9944,    28,   284,  3876,   130,  2196,    41,\n",
       "           196,     7,    75,   134,   784,  2122,     6,  2884, 13679,    27,\n",
       "             7,    75,  1265,    87,   196,     7,    76,   536,   784, 11071,\n",
       "          2596,     6,  2938,   908,    42,    27,  7331,  2596,    87,   196,\n",
       "             7,    26,  2596,   784,  2534,     6,  1808,   908,   137,     1,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'label_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'label_target_ids': tensor([2458,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'rationale_input_ids': tensor([32101,  5568,  5570,    10, 18921,  5027,    10,   611,     6,   149,\n",
       "          8072, 14727,    77,  6815,     7,    28,     8,  4163,    18,   134,\n",
       "          9068,  2392, 17282,  3379,  3048, 19363,    38,  1223,    80,    18,\n",
       "           235,    18,   782,  9944,    28,   284,  3876,   130,  2196,    41,\n",
       "           196,     7,    75,   134,   784,  2122,     6,  2884, 13679,    27,\n",
       "             7,    75,  1265,    87,   196,     7,    76,   536,   784, 11071,\n",
       "          2596,     6,  2938,   908,    42,    27,  7331,  2596,    87,   196,\n",
       "             7,    26,  2596,   784,  2534,     6,  1808,   908,   137,     1,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'rationale_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'rationale_target_ids': tensor([   37,     3, 13903,   795,  2625,     6,  9811,  1884,   161,     6,\n",
       "            42, 21603,     7,  1895,  1103,     5,     1,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0])}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/training_args.py:2243: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of 🤗 Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ====== Training Args ======\n",
    "# training_args = TrainingArguments( ## Original Training Args\n",
    "#     output_dir=\"gemma3-phase1\",\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     learning_rate=5e-5,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     save_strategy=\"epoch\",\n",
    "#     push_to_hub=False,\n",
    "#     remove_unused_columns=False\n",
    "# )\n",
    "\n",
    "## New Training Args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    # Disable fp16 for MPS devices\n",
    "    fp16=False,  # ← THIS IS CRUCIAL\n",
    "    bf16=True,   # You can try enabling this if you have newer hardware\n",
    "    use_mps_device=True,  # Explicitly enable MPS\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    save_strategy=\"no\",\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['base_input_ids', 'base_attention_mask', 'label_input_ids', 'label_attention_mask', 'label_target_ids', 'rationale_input_ids', 'rationale_attention_mask', 'rationale_target_ids'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trained_model_name = \"distilled_t5_on_1000_samples\"\n",
    "class MultiTaskTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None, **kwargs):\n",
    "        alpha = 0.3  # λ hyperparameter from the paper\n",
    "        ce_loss = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "        # Label Task ----------------------------------------------------------\n",
    "        # Create decoder inputs by shifting labels\n",
    "        label_decoder_input_ids = model._shift_right(inputs[\"label_target_ids\"])\n",
    "        \n",
    "        # Process Label Task --------------------------------------------------\n",
    "        label_outputs = model(\n",
    "            input_ids=inputs[\"label_input_ids\"],\n",
    "            attention_mask=inputs[\"label_attention_mask\"],\n",
    "            decoder_input_ids=label_decoder_input_ids,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        # Calculate loss for label prediction\n",
    "        label_loss = ce_loss(\n",
    "            label_outputs.logits.view(-1, model.config.vocab_size),\n",
    "            inputs[\"label_target_ids\"].view(-1)\n",
    "        )\n",
    "\n",
    "        # Process Rationale Task ----------------------------------------------\n",
    "        rationale_outputs = model(\n",
    "            input_ids=inputs[\"rationale_input_ids\"],\n",
    "            attention_mask=inputs[\"rationale_attention_mask\"],\n",
    "            labels=inputs[\"rationale_target_ids\"]\n",
    "        )\n",
    "        rationale_loss = rationale_outputs.loss\n",
    "\n",
    "        # Combine Losses ------------------------------------------------------\n",
    "        total_loss = (1 - alpha) * label_loss + alpha * rationale_loss\n",
    "\n",
    "        return (total_loss, (label_outputs, rationale_outputs)) if return_outputs else total_loss\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        # Handle both tasks during evaluation\n",
    "        with torch.no_grad():\n",
    "            loss = self.compute_loss(model, inputs)\n",
    "        \n",
    "        return (loss, None, None)  # (loss, predictions, labels)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = MultiTaskTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    data_collator=lambda data: {\n",
    "        \"label_input_ids\": torch.stack([d[\"label_input_ids\"] for d in data]),\n",
    "        \"label_attention_mask\": torch.stack([d[\"label_attention_mask\"] for d in data]),\n",
    "        \"label_target_ids\": torch.stack([d[\"label_target_ids\"] for d in data]),\n",
    "        \"rationale_input_ids\": torch.stack([d[\"rationale_input_ids\"] for d in data]),\n",
    "        \"rationale_attention_mask\": torch.stack([d[\"rationale_attention_mask\"] for d in data]),\n",
    "        \"rationale_target_ids\": torch.stack([d[\"rationale_target_ids\"] for d in data])\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 10/375 06:28 < 4:55:04, 0.02 it/s, Epoch 0.07/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(f\"./{new_trained_model_name}\")\n",
    "tokenizer.save_pretrained(f\"./{new_trained_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: \n",
      "Text: Chapel, as well as X10 [2], UPC [3] , CoArray Fortran [6], and Titanium [5], rely on the Partitioned...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: In addition, the result of the present study supports previous studies, which did not find increased...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Several instruments that more specifically address patient-reported outcomes following gastrectomy a...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: Organotypic hippocampal slice cultures\n",
      "Interface hippocampal slice cultures were prepared as describ...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: RESULTS\n",
      "Text: Activated PBMC are the basis of the standard PBMC blast assay for HIV-1 neutralization, whereas the ...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: Mouse embryonic fibroblasts (MEFs) were also infected with EOS (early transposon promoter and Oct-4 ...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: …the previous response, and as such, may be similar to the hippocampal “delay cells” described previ...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Therefore, we can compare our findings only with the data obtained by Koubek et al. (2004) who obtai...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: …as an ocs element (Bouchez et al. 1989; Lam et al. 1989), which was first characterized in the prom...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: After secondary review, 93 studies were included in the final report.(5-97) There were no randomized...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 3. Discussion\n",
      "Text: Another signi®cant result described in this report is the similarity of mNudE-L with the A. nidulans...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: 5%) reported a statistically significant improvement in the QOL of the intervention group [14, 20, 2...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: These data are consistent with previous reports that exposure of the developing brain to NMDA antago...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4. Discussion\n",
      "Text: This was expected, as the literature has shown that ethylene has an\n",
      "inhibitory effect on some forms ...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 3.4 Quantitative evaluation of the proposed segmentation method\n",
      "Text: In order to compare our method with [11], the results of both methods were assessed by a cardiologis...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: [12], is fast and simple to apply as positioning and irradiation can be performed in a short time....\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4.2 Adaptive validation\n",
      "Text: Then, for each DCT band, the parity bit stream is structured into sub-blocks of size MN 16P bits (on...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: As shown in previous studies done in other settings, our results demonstrate that the most clinicall...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Cancer\n",
      "Text: Due to the positive correlation between the development of cancer and the upregulation of Src activi...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: Briefly, iMyoD-transduced cells were seeded onto 24-well culture plates (Thermo Fisher Scientific, 3...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 2. Methods\n",
      "Text: Specifically, we used county-level 2013 rural-urban continuum codes linked to the national mortality...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Heart Function\n",
      "Text: disease patients who have had complete repair have a higher peak O2 compared to those have not, whic...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: Removal of androgens by castration results in thymus enlargement, whereas androgen replacement accel...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: We adopted the dosage of tramadol (4 mg/kg IV) based on previous reports on pharmacokinetics of an I...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: 1a), or individually via sharp electrode penetration within the ganglia (Krans and Chapple 2005)....\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: Similar biphasic profiles have been observed previously with reporter replicon systems derived from ...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: In addition, this study is also consistent with the results of the Colleoni et al [12] that more ves...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: In addition, pig cardiomyocytes have been shown to exhibit similar contraction rates and analogous a...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results and discussion\n",
      "Text: However, elevated levels of Fe (1537 mg/kg) and Cd (31.23 mg/kg) in agricultural soil samples (dry w...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4. Discussion\n",
      "Text: This pattern of response is consistent with previous results reported in the literature (Kokel et al...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: …measured immediately after each walking task.\n",
      "fNIRS measurement\n",
      "The details of the fNIRS system (OM...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: …Ranomafana National Park in 1992–1993 and Vohibola III in 2003–2005, research on temporal and geogr...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Method\n",
      "Text: …and valid across a number of studies (Evins and Theofrastous 1997), displays good sensitivity and s...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: According to the literature, the clinical results tend to worsen when more levels are involved in th...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4. Discussion\n",
      "Text: The abnormal histological alterations observed in group-HFD rats are consistent with those of previo...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4. Discussion\n",
      "Text: In this study, blood glucose concentration was evaluated because hyperglycaemia has been shown to re...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: The frequency of this behavior is of concern because of its potential association with impaired meta...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: Following evidence that the predictive power of SRH for subsequent morbidity and mortality risk may ...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: In [12,15], a list of trajectories, ordered in terms of risk, enables the surgeon to select the most...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Introduction\n",
      "Text: However, in these studies [5,13,15,16], patients generally had long-standing disease and were presum...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: \n",
      "Text: (ii) Velocity dependence of the sliding stress σs: For various types of such rough/rough multicontac...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 2.3 Enhancement methods\n",
      "Text: Given a source of prior knowledge, Gelly and Silver [3] proposed two directions to bootstrap UCT:\n",
      "1....\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: Over the past nearly 2 decades, Anaplasma and Ehrlichia species have emerged as major causes of tick...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4 Experiments\n",
      "Text: Methods such as SBDS [2, 18] avoid this problem but adding constraints to a model does not, so measu...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: [23] support this idea: only patients with DGF requiring more than one-time dialysis had an increase...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: \n",
      "Text: In [8], the authors proposed a wavelet-based MAR algorithm in which the missing projections are oned...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: …cortex, which is involved in taste pleasantness (Grabenhorst and Rolls, 2008), was more activated w...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: In order to activate reporter gene expression, we first treated the cells with H2O2/vanadate (pervan...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 3.4 Theory of Planned Behavior (TPB)\n",
      "Text: The Theory of Planned Behavior, introduced by Ajzen and his colleagues in social psychology [6], [8]...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: For mtDNA sequences, the number of haplotypes, gene diversity (Nei 1973), nucleotide diversity (Taji...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: Activation of 7- nAChRs by prolonged exposure to nicotine is known to alter gene transcription (Chan...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 2. Methodology\n",
      "Text: …d (subject to g > 0) gives the analytic solution\n",
      "ĝ = max {\n",
      "1 d 1 c (β̂ML − ν) >(X>WX)(β̂ML − ν)− 1...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: DISCUSSION\n",
      "Text: This suggestion is consistent with the current eye gaze literature, which indicates that human infan...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 3 Experiments\n",
      "Text: Most of the training parameters were fixed for all experiments: Adam [17] was used for optimisation ...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: nan\n",
      "Text: This type of extensive calcification within the lungs was first described by Harbitz (1918). The nam...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: In the lateral pyloric (LP) neuron of the lobster, IA slows the initial rate of depolarization of PI...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Although a large number of open clinical trials confirmed that glucocorticoids are effective in the ...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results and Discussion\n",
      "Text: In vitro studies have showed that Cd suppressed the viability of P. monodon haemocytes (Jose et al. ...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: In third-instar larvae, expression is seen in imaginal discs, including the eye imaginal disc, where...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: In diabetes mellitus, the choice of drugs or dosages is influenced by GFR.[57] Finally, we searched ...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: METHODS\n",
      "Text: Primers targeting RNase P/MRP 30 kDa subunit gene (RPP30; Gene ID: 10556; OMIM: 606115) were used fo...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: For both analyses, we first employ a Monte Carlo sampling technique for modeling the data [6]....\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results and analysis\n",
      "Text:  While presenting the statistics of sample companies distribution, authors say that size of the com...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 3.2 Results\n",
      "Text: Similar to [15], we also applied four popular subspace learning methods including PCA, LDA, LPP and ...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: Conceptual Model\n",
      "For BN model development we followed the guidelines provided by Cain (2001), Marcot...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4. Experiments\n",
      "Text: We choose the NYU dataset to conduct ablation experiments and compare against the baseline methods s...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: NSE levels are notably higher in extensive than limited stage disease (Carney et al., 1982; Johnson ...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: DNA-based replicons (for DENV type 1) expressing secreted Gaussia luciferase (DGL2 and DGL2-mut) [30...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: METHODS\n",
      "Text: The nuclear-targeted cameleon calcium sensor (Sieberer et al., 2009) was excitedwith the argon ion 4...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4. Discussion\n",
      "Text: It has also been reported that monensin is more toxic to humanmonocytes in peripheral blood (Schuerw...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: \n",
      "Text: In order to examine the availability of the negotiation protocol, we have employed the ASCML[8](Agen...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Cobalamin is required for conversion of methylfolate to the active form tetrahydrofolate, which is r...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: Lactate is thought to instantaneously replenish neuronal energy needs by generating NADH (Pellerin a...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: Secondary structure match score between the predicted\n",
      "secondary structures from sequence by PSIPRED ...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 2.1. Theoretical considerations\n",
      "Text: In further examining the styles of fractionation present in natural systems, fractionations are ofte...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: This effect has been ascribed to relief from the inhibition of cell firing exerted by endogenous 5-H...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: There have been several studies reporting the association between low or high dose of statin and acu...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Moreover, with the number of reported patients usually varying from less than 15 to about 50 [6, 8, ...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 5. Experiments\n",
      "Text: Competitors We compared the proposed SLST model with five state-of-the-art alternative detection app...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 3. Discussion\n",
      "Text: In head and neck cancers, expression of the S100A3 gene is upregulated in comparison to normal mucos...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: METHODS\n",
      "Text: Intercept terms were excluded from these trivariate probit models to facilitate identification on la...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Phylogenetic analysis\n",
      "Text: A multiple alignment of the hypervariable region of 95 18S rRNA gene sequences comprising selected a...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: GATA3 inhibits tumor formation in the breast, but promotes carcinogenesis in lymphoid precursor cell...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Up to date, the high GC content (Blacket et al. 2012) and modified M13-based universal primers with ...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Lately, interesting reports have been issued on prognostic significance of beta-catenin nuclear expr...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4. Discussion\n",
      "Text: Indeed, obstructive sleep apnoea is commonly caused by failure to maintain the patency of the upper ...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: There is increasing mechanistic evidence providing biological plausibility that smoking increases th...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: \n",
      "Text: Conventional TEM has shown the presence of these outer membrane derived vesicles, particularly for P...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Secondary 57 (31) 99 (41) 91 (37) 97 (39) 66 (37) 84 (34) 83 (34) 78 (38) 86 (40)...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Surface Plasmon Resonance\n",
      "Text: More sensitive that IgM ELISA\n",
      "- Small sample volume required and\n",
      "rapid completion rate\n",
      "- Requires sp...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Materials and Methods\n",
      "Text: The plasma levels of FFA and total cholesterol were determined using their respective enzymatic kits...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Sequence analysis\n",
      "Text: %) from Dianthus caryophyllus(Britsch et al., 1993), and a leucoanthocyanidin dioxygenase fromPerill...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 92 piglets\n",
      "Text: Furthermore, the fear-related behaviour is closely associated with the stress response regulated by ...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Variability in pain sensitivity over time and between subjects is typical following human SCI (Cruz-...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: \n",
      "Text: …Rosenhall, 1971; Hirokawa, 1978; Tanaka and Smith, 1978; Firbas and Mtiller, 1983; Tilney and Saund...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 2. Methods\n",
      "Text: The inclination with respect to gravity of the IMU located on the wheelchair backrest was computed d...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Our study is among the first to evaluate both PIK3CA mutations and PTEN protein expression status in...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: …et al. (1995) suggested that there is a strong relationship between the structure of zooplankton as...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: [11] report that increased dietary calcium was associated with increased risk of RCC, but the effect...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: METHODS\n",
      "Text: Prisoners completed the Eysenck Personality Questionnaire (EPQ) (Eysenck & Eysenck, 1975), from whic...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: Data for this matched-cohort study come from 3 Canadian administrative databases: (1) one large Cana...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: …increased risk of BC associated with DM Talamini et al. (1997) CC 2769 2588 Non-specific Increased ...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Introduction\n",
      "Text: …Hunan Province, The College of Information Science and Engineering, Hunan University, Changsha 4100...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 2 Method\n",
      "Text: The default synthetic voice that we used featured a well established corpus-based prosodic model [11...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: \n",
      "Text: ERalpha is the predominant estrogen receptor in the VMH and is found in neurons throughout the rostr...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4. Discussion\n",
      "Text: Despite the medical importance of lectins [2,5,8], little information is available about the transpo...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Methods\n",
      "Text: Atrial myocytes were isolated by enzymatic dissociation and mechanical disaggregation, as described ...\n",
      "True: method | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 4390 J O U R N A L O F P R O T E O M I C S 7 5 ( 2 0 1 2 ) 4 3 8 1 – 4 3 9 8\n",
      "Text: In the present study we could confirm that r>0.68 could be calculated for CKM and GAPDH in relation ...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: 1 Introduction\n",
      "Text: This is the first complete complexity classification of general-valued languages over non-Boolean do...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Results\n",
      "Text: These substances are not representative of the data used in setting the values for the Cramer classe...\n",
      "True: background | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Section: Discussion\n",
      "Text: Our results agreed with those of others (Darlington & Matson, 1999; Kovacs et al., 2003; Elford et a...\n",
      "True: result | Pred: unknown\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m inputs \u001b[38;5;241m=\u001b[39m preprocess_input(example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m\"\u001b[39m], example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Get prediction\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m raw_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m cleaned_label \u001b[38;5;241m=\u001b[39m clean_prediction(raw_pred)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Store results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[91], line 43\u001b[0m, in \u001b[0;36mpredict_label\u001b[0;34m(model, inputs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate label prediction\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 43\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# For deterministic results (default):\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Disables sampling\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Beam search works better for Seq2Seq\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Remove temperature parameter when do_sample=False\u001b[39;49;00m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_start_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#critical for T5\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"method\"),\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# eos_token_id=tokenizer.eos_token_id,\u001b[39;49;00m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Debug raw outputs\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw output IDs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/generation/utils.py:2482\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2475\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2476\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2477\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2478\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2479\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2480\u001b[0m     )\n\u001b[1;32m   2481\u001b[0m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2482\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2492\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2493\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2494\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2495\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2501\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2502\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/generation/utils.py:3902\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3899\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3900\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m-> 3902\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3904\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3905\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3906\u001b[0m     model_outputs,\n\u001b[1;32m   3907\u001b[0m     model_kwargs,\n\u001b[1;32m   3908\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3909\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1905\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1902\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1905\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1921\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1131\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1115\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1116\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         cache_position,\n\u001b[1;32m   1129\u001b[0m     )\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:682\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    668\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    680\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    681\u001b[0m ):\n\u001b[0;32m--> 682\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m     hidden_states, past_key_value \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    693\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:599\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    590\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    597\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m ):\n\u001b[0;32m--> 599\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSelfAttention(\n\u001b[1;32m    601\u001b[0m         normed_hidden_states,\n\u001b[1;32m    602\u001b[0m         mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    609\u001b[0m     )\n\u001b[1;32m    610\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:257\u001b[0m, in \u001b[0;36mT5LayerNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# T5 uses a layer_norm which only scales and doesn't shift, which is also known as Root Mean\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# Square Layer Normalization https://arxiv.org/abs/1910.07467 thus variance is calculated\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# w/o mean and there is no bias. Additionally we want to make sure that the accumulation for\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# half-precision inputs is done in fp32\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 257\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariance_epsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# convert into half-precision if necessary\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39mfloat16, torch\u001b[38;5;241m.\u001b[39mbfloat16]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Configuration\n",
    "model_path = f\"./{new_trained_model_name}\" ## TODO: Note that this model is trained only on a 1000 samples! Because the paper says 25% of full training ata was alr good enough, so i wanted to just test with a smaller number of samples first.\n",
    "test_data_path = \"../data/test.jsonl\"\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load the distilled model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# After loading tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path, trust_remote_code=True, torch_dtype=torch.float32).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "def load_test_data(file_path):\n",
    "    \"\"\"Load and parse test data\"\"\"\n",
    "    test_data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            test_data.append({\n",
    "                \"section\": entry[\"sectionName\"],\n",
    "                \"text\": entry[\"string\"],\n",
    "                \"true_label\": entry[\"label\"]\n",
    "            })\n",
    "    return test_data\n",
    "\n",
    "def preprocess_input(section, text):\n",
    "    \"\"\"Format input with task prefix\"\"\"\n",
    "    input_text = f\"[label] Section: {section}\\nText: {text}\\nLabel:\" ## TODO: NOTE THAT THIS IS KEYyyyy\n",
    "    return tokenizer(\n",
    "        input_text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "def predict_label(model, inputs):\n",
    "    \"\"\"Generate label prediction\"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=10,\n",
    "            # For deterministic results (default):\n",
    "            do_sample=False,  # Disables sampling\n",
    "            num_beams=3,     # Beam search works better for Seq2Seq\n",
    "            early_stopping=False,\n",
    "            # Remove temperature parameter when do_sample=False\n",
    "            decoder_start_token_id=tokenizer.pad_token_id, #critical for T5\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            # forced_bos_token_id=tokenizer.convert_tokens_to_ids(\"method\"),\n",
    "            # eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    # Debug raw outputs\n",
    "    print(\"Raw output IDs:\", outputs[0])\n",
    "    # print(\"Decoded output:\", tokenizer.decode(outputs[0]))\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def clean_prediction(raw_prediction):\n",
    "    \"\"\"Extract label from model output\"\"\"\n",
    "    # Split on \"Label:\" and take the first word after it\n",
    "    print(f\"Raw: {raw_prediction}\")\n",
    "    # parts = raw_prediction.split(\"Label:\")\n",
    "    if len(raw_prediction) > 1:\n",
    "        prediction = raw_prediction.strip().split()[0].lower()\n",
    "        # Map to valid labels\n",
    "        valid_labels = {\"background\", \"method\", \"result\"}\n",
    "        print(f\"Prediction: {prediction}\")\n",
    "        return prediction if prediction in valid_labels else \"unknown\"\n",
    "    return \"unknown\"\n",
    "\n",
    "# Load test data\n",
    "test_data = load_test_data(test_data_path)\n",
    "\n",
    "# Run predictions\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "for example in test_data:\n",
    "    # Preprocess input\n",
    "    inputs = preprocess_input(example[\"section\"], example[\"text\"])\n",
    "    \n",
    "    # Get prediction\n",
    "    raw_pred = predict_label(model, inputs)\n",
    "    cleaned_label = clean_prediction(raw_pred)\n",
    "    \n",
    "    # Store results\n",
    "    true_labels.append(example[\"true_label\"])\n",
    "    pred_labels.append(cleaned_label)\n",
    "    \n",
    "    # Print example (optional)\n",
    "    print(f\"Section: {example['section']}\")\n",
    "    print(f\"Text: {example['text'][:100]}...\")\n",
    "    print(f\"True: {example['true_label']} | Pred: {cleaned_label}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save results\n",
    "with open(\"predictions_t5_trained.csv\", \"w\") as f:\n",
    "    f.write(\"true_label,predicted_label\\n\")\n",
    "    for true, pred in zip(true_labels, pred_labels):\n",
    "        f.write(f\"{true},{pred}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Comparison (Base vs Distilled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Base Model:  20%|██        | 1/5 [00:01<00:05,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([    0,  5481,   254,    18, 26296,  4652,   188,   357,   516,     1],\n",
      "       device='mps:0')\n",
      "Raw: HPC-EUROPA2 project\n",
      "Prediction: hpc-europa2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Base Model:  40%|████      | 2/5 [00:01<00:02,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([    0, 32099, 16330,  5027,    10,    86,   811,     6,     8,   915,\n",
      "          810], device='mps:0')\n",
      "Raw: Discussion Text: In addition, the present study\n",
      "Prediction: discussion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Base Model:  60%|██████    | 3/5 [00:02<00:01,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([    0, 32099,     5, 32098,  5568,    10, 16330,  5027,    10,     3,\n",
      "         8656], device='mps:0')\n",
      "Raw: . Section: Discussion Text: Several\n",
      "Prediction: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Base Model:  80%|████████  | 4/5 [00:02<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([    0, 10747,     7,    15,     1], device='mps:0')\n",
      "Raw: False\n",
      "Prediction: false\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Base Model: 100%|██████████| 5/5 [00:02<00:00,  1.75it/s]\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([    0, 10747,     7,    15,     1], device='mps:0')\n",
      "Raw: False\n",
      "Prediction: false\n",
      "Saved predictions to base_model_predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Distilled Model:  20%|██        | 1/5 [00:02<00:08,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Distilled Model:  40%|████      | 2/5 [00:03<00:05,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Distilled Model:  60%|██████    | 3/5 [00:05<00:03,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Distilled Model:  80%|████████  | 4/5 [00:06<00:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Distilled Model: 100%|██████████| 5/5 [00:07<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "Saved predictions to distilled_model_predictions.csv\n",
      "\n",
      "Performance Comparison:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/ethanyuxin/anaconda3/envs/ai/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4dd47_row0_col1, #T_4dd47_row1_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4dd47\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4dd47_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_4dd47_level0_col1\" class=\"col_heading level0 col1\" >accuracy</th>\n",
       "      <th id=\"T_4dd47_level0_col2\" class=\"col_heading level0 col2\" >precision_background</th>\n",
       "      <th id=\"T_4dd47_level0_col3\" class=\"col_heading level0 col3\" >recall_background</th>\n",
       "      <th id=\"T_4dd47_level0_col4\" class=\"col_heading level0 col4\" >precision_method</th>\n",
       "      <th id=\"T_4dd47_level0_col5\" class=\"col_heading level0 col5\" >recall_method</th>\n",
       "      <th id=\"T_4dd47_level0_col6\" class=\"col_heading level0 col6\" >precision_result</th>\n",
       "      <th id=\"T_4dd47_level0_col7\" class=\"col_heading level0 col7\" >recall_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4dd47_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4dd47_row0_col0\" class=\"data row0 col0\" >Base Model</td>\n",
       "      <td id=\"T_4dd47_row0_col1\" class=\"data row0 col1\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row0_col2\" class=\"data row0 col2\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row0_col3\" class=\"data row0 col3\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row0_col4\" class=\"data row0 col4\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row0_col5\" class=\"data row0 col5\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row0_col6\" class=\"data row0 col6\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row0_col7\" class=\"data row0 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4dd47_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4dd47_row1_col0\" class=\"data row1 col0\" >Distilled Model</td>\n",
       "      <td id=\"T_4dd47_row1_col1\" class=\"data row1 col1\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row1_col2\" class=\"data row1 col2\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row1_col3\" class=\"data row1 col3\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row1_col4\" class=\"data row1 col4\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row1_col5\" class=\"data row1 col5\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row1_col6\" class=\"data row1 col6\" >0.00%</td>\n",
       "      <td id=\"T_4dd47_row1_col7\" class=\"data row1 col7\" >0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x39d5daf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Prediction Comparison:\n",
      "Raw output IDs: tensor([    0,  5481,   254,    18, 26296,  4652,   188,   357,   516,     1],\n",
      "       device='mps:0')\n",
      "Raw: HPC-EUROPA2 project\n",
      "Prediction: hpc-europa2\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "\n",
      "Section: \n",
      "Text: Chapel, as well as X10 [2], UPC [3] , CoArray Fortran [6], and Titanium [5], rely on the Partitioned...\n",
      "True Label: background\n",
      "Base Model: unknown | Distilled Model: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([    0, 32099, 16330,  5027,    10,    86,   811,     6,     8,   915,\n",
      "          810], device='mps:0')\n",
      "Raw: Discussion Text: In addition, the present study\n",
      "Prediction: discussion\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "\n",
      "Section: Discussion\n",
      "Text: In addition, the result of the present study supports previous studies, which did not find increased...\n",
      "True Label: result\n",
      "Base Model: unknown | Distilled Model: unknown\n",
      "--------------------------------------------------------------------------------\n",
      "Raw output IDs: tensor([    0, 32099,     5, 32098,  5568,    10, 16330,  5027,    10,     3,\n",
      "         8656], device='mps:0')\n",
      "Raw: . Section: Discussion Text: Several\n",
      "Prediction: .\n",
      "Raw output IDs: tensor([0, 0], device='mps:0')\n",
      "Raw: \n",
      "\n",
      "Section: Discussion\n",
      "Text: Several instruments that more specifically address patient-reported outcomes following gastrectomy a...\n",
      "True Label: background\n",
      "Base Model: unknown | Distilled Model: unknown\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_and_save(model, tokenizer, test_data, model_name=\"Model\", save_path=None):\n",
    "    \"\"\"Evaluate model and save predictions to CSV\"\"\"\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    raw_preds = []\n",
    "    sections = []\n",
    "    texts = []\n",
    "    \n",
    "    for example in tqdm(test_data, desc=f\"Evaluating {model_name}\"):\n",
    "        inputs = preprocess_input(example[\"section\"], example[\"text\"])\n",
    "        raw_pred = predict_label(model, inputs)\n",
    "        cleaned_label = clean_prediction(raw_pred)\n",
    "        \n",
    "        # Collect data for CSV\n",
    "        sections.append(example[\"section\"])\n",
    "        texts.append(example[\"text\"])\n",
    "        true_labels.append(example[\"true_label\"])\n",
    "        pred_labels.append(cleaned_label)\n",
    "        raw_preds.append(raw_pred)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        \"section\": sections,\n",
    "        \"text\": texts,\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted_label\": pred_labels,\n",
    "        \"raw_prediction\": raw_preds\n",
    "    })\n",
    "    \n",
    "    # Save to CSV if path specified\n",
    "    if save_path:\n",
    "        results_df.to_csv(save_path, index=False)\n",
    "        print(f\"Saved predictions to {save_path}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    class_report = classification_report(true_labels, pred_labels, output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision_background\": class_report[\"background\"][\"precision\"],\n",
    "        \"recall_background\": class_report[\"background\"][\"recall\"],\n",
    "        \"precision_method\": class_report[\"method\"][\"precision\"],\n",
    "        \"recall_method\": class_report[\"method\"][\"recall\"],\n",
    "        \"precision_result\": class_report[\"result\"][\"precision\"],\n",
    "        \"recall_result\": class_report[\"result\"][\"recall\"],\n",
    "    }\n",
    "#%% [markdown]\n",
    "#### 1. Load Base Model (Pre-trained)\n",
    "#%%\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\").to(device)\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(\"t5-base\") \n",
    "\n",
    "# Add special tokens if missing\n",
    "special_tokens = [\"[label]\", \"[rationale]\"]\n",
    "base_tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
    "base_model.resize_token_embeddings(len(base_tokenizer))\n",
    "\n",
    "#%% [markdown]\n",
    "#### 2. Load Distilled Model (Fine-tuned)\n",
    "#%%\n",
    "distilled_model = AutoModelForSeq2SeqLM.from_pretrained(f\"./{new_trained_model_name}\").to(device)\n",
    "distilled_tokenizer = AutoTokenizer.from_pretrained(f\"./{new_trained_model_name}\")\n",
    "\n",
    "#%% [markdown]\n",
    "#### 3. Evaluate Both Models\n",
    "#%%\n",
    "test_data = load_test_data(test_data_path)[:5]  # Use subset for faster evaluation\n",
    "\n",
    "# Evaluate base model and save\n",
    "base_results = evaluate_and_save(\n",
    "    base_model, \n",
    "    base_tokenizer,\n",
    "    test_data,\n",
    "    model_name=\"Base Model\",\n",
    "    save_path=\"base_model_predictions.csv\"\n",
    ")\n",
    "\n",
    "# Evaluate distilled model and save\n",
    "distilled_results = evaluate_and_save(\n",
    "    distilled_model,\n",
    "    distilled_tokenizer,\n",
    "    test_data,\n",
    "    model_name=\"Distilled Model\",\n",
    "    save_path=\"distilled_model_predictions.csv\"\n",
    ")\n",
    "\n",
    "#%% [markdown]\n",
    "#### 4. Display Comparison\n",
    "#%%\n",
    "results_df = pd.DataFrame([base_results, distilled_results])\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "display(results_df.style\n",
    "       .format(\"{:.2%}\", subset=[\"accuracy\", \"precision_background\", \"recall_background\", \n",
    "                                \"precision_method\", \"recall_method\", \n",
    "                                \"precision_result\", \"recall_result\"])\n",
    "       .background_gradient(cmap=\"Blues\", subset=[\"accuracy\"]))\n",
    "\n",
    "#%% [markdown]\n",
    "#### 5. Sample Predictions Comparison\n",
    "#%%\n",
    "print(\"\\nSample Prediction Comparison:\")\n",
    "sample_data = test_data[:3]  # First 3 examples\n",
    "\n",
    "for example in sample_data:\n",
    "    # Base model prediction\n",
    "    inputs = preprocess_input(example[\"section\"], example[\"text\"])\n",
    "    base_pred = clean_prediction(predict_label(base_model, inputs))\n",
    "    \n",
    "    # Distilled model prediction\n",
    "    inputs = preprocess_input(example[\"section\"], example[\"text\"])\n",
    "    distilled_pred = clean_prediction(predict_label(distilled_model, inputs))\n",
    "    \n",
    "    print(f\"\\nSection: {example['section']}\")\n",
    "    print(f\"Text: {example['text'][:100]}...\")\n",
    "    print(f\"True Label: {example['true_label']}\")\n",
    "    print(f\"Base Model: {base_pred} | Distilled Model: {distilled_pred}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
