{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shawn Kok\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gemma3ForCausalLM(\n",
       "  (model): Gemma3TextModel(\n",
       "    (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 1152, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma3DecoderLayer(\n",
       "        (self_attn): Gemma3Attention(\n",
       "          (q_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1152, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1152, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): Linear(in_features=1152, out_features=256, bias=False)\n",
       "          (v_proj): lora.Linear(\n",
       "            (base_layer): Linear(in_features=1152, out_features=256, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=1152, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): Linear(in_features=1024, out_features=1152, bias=False)\n",
       "          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Gemma3MLP(\n",
       "          (gate_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
       "          (up_proj): Linear(in_features=1152, out_features=6912, bias=False)\n",
       "          (down_proj): Linear(in_features=6912, out_features=1152, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "    (rotary_emb): Gemma3RotaryEmbedding()\n",
       "    (rotary_emb_local): Gemma3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1152, out_features=262144, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model = \"./gemma3-phase1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(trained_model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 samples from dataset.\n"
     ]
    }
   ],
   "source": [
    "# ====== Load dataset ======\n",
    "def load_partition(path: str) -> Dataset:\n",
    "    df = pd.read_csv(path).head(10)\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "dataset = load_partition(\"./Student_Training_Data/GPT.csv\")\n",
    "\n",
    "print(f\"Loaded {len(dataset)} samples from dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shawn Kok\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Shawn Kok\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `64` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: However, how frataxin interacts with the Fe-S cluster biosynthesis components remains unclear as direct one-to-one interactions with each component were reported (IscS [12,22], IscU/Isu1 [6,11,16] or ISD11/Isd11 [14,15]).\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "**JSON Output:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes an investigation into the interaction between frataxin and Fe-S cluster biosynthesis components, which is a core aspect of a scientific method.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n",
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: In the study by Hickey et al. (2012), spikes were sampled from the field at the point of physiological robinson et al.: genomic regions influencing root traits in barley 11 of 13 maturity, dried, grain threshed by hand, and stored at −20C to preserve grain dormancy before germination testing.\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes a method used in the study, specifically the sampling of spikes from the field and the subsequent processing of the data. It doesn't present a theoretical explanation or background information.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n",
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: The drug also reduces catecholamine secretion, thereby reducing stress and leading to a modest (10-20%) reduction in heart rate and blood pressure, which may be particularly beneficial in patients with cardiovascular disease.(7) Unlike midazolam, dexmedetomidine does not affect the ventilatory response to carbon dioxide.\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes a pharmacological effect of the drug – reducing catecholamine secretion – and its subsequent impact on physiological parameters like heart rate and blood pressure. This is a core aspect of how the drug works, and therefore falls under the 'method' category.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n",
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: By clustering with lowly aggressive close kin (King 1989a,b; Viblanc et al. 2010; Arnaud, Dobson & Murie 2012), breeding females may decrease the time/energy cost of maintaining territorial boundaries (Festa-Bianchet & Boag 1982; Murie & Harris 1988), which could ultimately lead to increases in net energy income (TA) or higher allocations in somatic or reproductive functions.\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes a method – clustering with closely related females – to investigate a phenomenon. It's not a description of a general principle, but a specific procedure.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n",
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: Ophthalmic symptoms are rare manifestations of the intracranial arachnoid cyst, and include unilateral exophthalmos, visual field abnormality, decreased visual acuity and isolated palsies of the third, fourth and sixth cranial nerves [1–5].\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes the symptoms of an arachnoid cyst, which is a clinical observation. It's not a procedure or a measurement, but rather a description of a condition.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n",
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: Recent studies identified Wee1 as a potential molecular target in cancer cells and the selective small molecule Wee1-inhibitor MK-1775 demonstrated promising results in cancer cells with enhanced levels of Wee1 (96-98).\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes a study that identified Wee1 as a potential target and tested a specific inhibitor (MK-1775) on cancer cells. This is a core aspect of the scientific method.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n",
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: These problems combine to make early diagnosis essential and immediate treatment a necessity, even for the youngest patients [17, 18].\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes a problem and its importance, which is a core aspect of the method of analyzing scientific text.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n",
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: Also, results demonstrated that the molecular weight and G/M ratio were important factors in controlling the antioxidant properties of sodium alginate (Şen 2011).\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes a method of investigating the antioxidant properties of sodium alginate, specifically mentioning the importance of molecular weight and G/M ratio.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n",
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: Recently, the light-induced method, which is based on the changes of surface wettability of certain materials [12], has been developed and provides amore convenient approach for cell harvesting [13].\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes a method (light-induced method) for harvesting cells. It's a specific procedure or technique.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n",
      "Generated: <instruction>Classify the following scientific text as one of [background, method, result].\n",
      "\n",
      "Text: Currently, with advances in radiotherapeutic, chemotherapeutic, and surgical techniques, limb-salvage surgery has become an accepted treatment [2–9].\n",
      "Provide your classification and reasoning in JSON format.</instruction>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"classification\": \"method\",\n",
      "  \"reasoning\": \"The text describes a treatment (limb-salvage surgery) and its acceptance as a treatment option, which is a core aspect of the method.\"\n",
      "}\n",
      "```\n",
      " \n",
      " Predicted: no_response\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for example in dataset:\n",
    "    prompt = (\n",
    "        \"<instruction>Classify the following scientific text as one of [background, method, result].\\n\\n\"\n",
    "        f\"Text: {example['string']}\\n\"\n",
    "        \"Provide your classification and reasoning in JSON format.</instruction>\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=100,\n",
    "            do_sample=False,\n",
    "            num_beams=1\n",
    "        )\n",
    "\n",
    "    generated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # generated output will be in this format: <response>{\"classification\": \"method\", \"reasoning\": \"It describes the method used...\"}\n",
    "    if \"<response>\" in generated:\n",
    "        json_start = generated.split(\"<response>\")[-1].strip()\n",
    "        try:\n",
    "            parsed = json.loads(json_start)\n",
    "            classification = parsed.get(\"classification\", \"\")\n",
    "            reasoning = parsed.get(\"reasoning\", \"\")\n",
    "        except json.JSONDecodeError:\n",
    "            classification = \"parse_error\"\n",
    "            reasoning = \"Could not parse output.\"\n",
    "    else:\n",
    "        classification = \"no_response\"\n",
    "        reasoning = \"Missing <response> tag.\"\n",
    "\n",
    "    predictions.append({\n",
    "        \"predicted_classification\": classification,\n",
    "        \"predicted_reasoning\": reasoning\n",
    "    })\n",
    "    print(f\"Generated: {generated} \\n Predicted: {classification}\")\n",
    "\n",
    "# ====== Save to CSV ======\n",
    "df = dataset.to_pandas()\n",
    "df[\"predicted_classification\"] = [p[\"predicted_classification\"] for p in predictions]\n",
    "df[\"predicted_reasoning\"] = [p[\"predicted_reasoning\"] for p in predictions]\n",
    "df.to_csv(\"gemma3_classification_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference step here\n",
    "def generate_output(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=50)\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    text_input = row[\"string\"]\n",
    "    predicted_label = generate_output(text_input)\n",
    "    predictions.append(predicted_label)\n",
    "    print(\"classification: \", predicted_label)\n",
    "\n",
    "# Save to DataFrame\n",
    "dataset[\"predicted_classification\"] = predictions\n",
    "dataset.to_csv(\"gemma3_classification_results.csv\", index=False)\n",
    "print(\"Inference for first 10 data points completed.\")\n",
    "# Save results\n",
    "# dataset = dataset.add_column(\"generated_reasoning\", predictions)\n",
    "# output_csv_path = \"./llama-student-phase2.csv\"\n",
    "# dataset.to_pandas().to_csv(output_csv_path, index=False)\n",
    "\n",
    "# print(f\"Inference completed. Results saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Index {i}: {prediction} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
